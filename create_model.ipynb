{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from snownlp import SnowNLP\n",
    "from sklearn.externals import joblib\n",
    "from snownlp import sentiment\n",
    "\n",
    "# 生成模型，测试意见内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 94)\t1.0\n",
      "  (2, 94)\t1.0\n",
      "  (3, 95)\t1.0\n",
      "  (4, 97)\t1.0\n",
      "  (5, 97)\t1.0\n",
      "  (6, 98)\t1.0\n",
      "  (7, 99)\t1.0\n",
      "  (8, 100)\t1.0\n",
      "  (9, 102)\t1.0\n",
      "  (10, 103)\t1.0\n",
      "  (11, 104)\t1.0\n",
      "  (12, 105)\t1.0\n",
      "  (13, 106)\t1.0\n",
      "  (15, 119)\t1.0\n",
      "  (16, 128)\t0.802818814511\n",
      "  (16, 2601)\t0.596223071566\n",
      "  (17, 142)\t1.0\n",
      "  (18, 142)\t1.0\n",
      "  (19, 142)\t1.0\n",
      "  (20, 142)\t1.0\n",
      "  (21, 94)\t0.661883286007\n",
      "  (21, 147)\t0.749606907455\n",
      "  (22, 94)\t0.681481731797\n",
      "  (22, 165)\t0.731835124346\n",
      "  (23, 177)\t1.0\n",
      "  :\t:\n",
      "  (1844, 882)\t0.214542817705\n",
      "  (1844, 335)\t0.230192063101\n",
      "  (1844, 669)\t0.247200518022\n",
      "  (1844, 814)\t0.237621852949\n",
      "  (1844, 1280)\t0.260700888193\n",
      "  (1844, 250)\t0.260700888193\n",
      "  (1844, 850)\t0.260700888193\n",
      "  (1844, 2745)\t0.521401776385\n",
      "  (1845, 2601)\t0.38031490946\n",
      "  (1845, 2616)\t0.394909305752\n",
      "  (1845, 1681)\t0.394909305752\n",
      "  (1845, 1130)\t0.364854227376\n",
      "  (1845, 1072)\t0.384827293089\n",
      "  (1845, 1856)\t0.512096863262\n",
      "  (1846, 2502)\t0.361443985539\n",
      "  (1846, 648)\t0.687895647228\n",
      "  (1846, 726)\t0.629410695684\n",
      "  (1847, 1499)\t0.366196875458\n",
      "  (1847, 336)\t0.350299552475\n",
      "  (1847, 585)\t0.521051133499\n",
      "  (1847, 2311)\t0.686801127125\n",
      "  (1848, 2502)\t0.310300021088\n",
      "  (1848, 2321)\t0.360381053848\n",
      "  (1848, 1433)\t0.60962026708\n",
      "  (1848, 432)\t0.634194388895\n"
     ]
    }
   ],
   "source": [
    "# 导入训练数据\n",
    "data = pd.read_excel('feedback.xlsx')\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "# 获取分类集和数据集\n",
    "classification = np.array(data[:, 0], dtype='int')\n",
    "comment = np.array(data[:, 1], dtype='object')\n",
    "\n",
    "# 对数据集（文本）进行分词\n",
    "commentStack = [];\n",
    "for number in range(len(comment)):\n",
    "    commentWord = jieba.cut(str(comment[number]))\n",
    "    commentWord = \" \".join(commentWord)\n",
    "    commentStack.append(commentWord)\n",
    "\n",
    "#转化成数组，格式是[\"词语1 词语2 词语3\"， ...] 一个元素代表一个文本\n",
    "vectorizer = CountVectorizer()    # 计算文本的词频矩阵\n",
    "arr = vectorizer.fit_transform(commentStack)  # 矩阵元素a[i][j] 表示j词在i个文本下的词频\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(arr) # 传入词频向量计算tf-idf\n",
    "\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 朴素贝叶斯统计\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(tfidf, classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment.train('feedback_negative.txt', 'feedback_positive.txt')\n",
    "sentiment.save('sentiment.marshal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05073435  0.32995416  0.04215937  0.57715211]]\n",
      "0.9808587058313183\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "test_comment = u'最满意的炒股软件'\n",
    "\n",
    "test_comment = jieba.cut(test_comment)\n",
    "test_comment = \" \".join(test_comment)\n",
    "\n",
    "test_comment = [test_comment]\n",
    "\n",
    "test_vectorizer_wordFrequency = vectorizer.transform(test_comment)\n",
    "\n",
    "test_tfidf = transformer.transform(test_vectorizer_wordFrequency).toarray()\n",
    "\n",
    "predict_classification = mnb.predict(test_tfidf)\n",
    "predict_classification_proba = mnb.predict_proba(test_tfidf)\n",
    "\n",
    "print(predict_classification_proba)\n",
    "\n",
    "snownlp = SnowNLP(str(test_comment))\n",
    "snow_score = snownlp.sentiments\n",
    "\n",
    "print(snow_score)\n",
    "\n",
    "# 如果snow判断大于0.8或朴素贝叶斯预测值大于0.8，则选择作为分类\n",
    "# snow_tag_stack = {0:0.25, 1:0.5, 2:0.75, 3:1}\n",
    "\n",
    "naive_score = predict_classification_proba[0][predict_classification[0]]     # 朴素贝叶斯得到的最大分类概率\n",
    "\n",
    "if (snow_score >= 0.5):\n",
    "    if (snow_score >= naive_score):      # 如果情感分析得分大于朴素贝叶斯最大概率，则选择该标签\n",
    "        final_score = snow_score\n",
    "        if (snow_score > 0.25):\n",
    "            if (snow_score > 0.5):\n",
    "                if (snow_score > 0.75):\n",
    "                    tag = 3              # 标记为3分满意\n",
    "                else:\n",
    "                    tag = 2              # 标记为中肯\n",
    "            else:\n",
    "                tag = 1\n",
    "        else:\n",
    "            tag = 0\n",
    "    else:\n",
    "        final_score = naive_score\n",
    "        tag = predict_classification[0]\n",
    "else:\n",
    "    snow_score = 1-snow_score\n",
    "    if (snow_score >= naive_score):      # 如果情感分析得分大于朴素贝叶斯最大概率，则选择该标签\n",
    "        final_score = snow_score\n",
    "        if (snow_score > 0.5):\n",
    "            if (snow_score > 0.75):\n",
    "                tag = 0\n",
    "            else:\n",
    "                tag = 1\n",
    "    else:\n",
    "        final_score = naive_score\n",
    "        tag = predict_classification[0]\n",
    "    \n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10jqka_vectorizer']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mnb, '10jqka_mnb')\n",
    "joblib.dump(transformer, '10jqka_transformer')\n",
    "joblib.dump(vectorizer, '10jqka_vectorizer')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
